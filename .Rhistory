diff <- mean(frs)-mean(nfrs)
xbarholder[i] <- diff
if(abs(diff) > observed_diff)
counter <- counter + 1
}
Fired = c(34, 37, 37, 38, 41, 42, 43, 44, 44, 45, 45, 45, 46, 48, 49, 53, 53, 54, 54, 55, 56)
Notfired = c(27, 33, 36, 37, 38, 38, 39, 42, 42, 43, 43, 44, 44, 44, 45, 45, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 51, 51, 52, 54)
fired <- rep('Fired', 21)
notfired <- rep('Notfired', 30)
ages <- as.factor(c(fired, notfired))
all.ages <- data.frame(name=ages, combo=c(Fired, Notfired))
number_of_permutations <- 10
xbarholder <- numeric(0)
counter <- 0
observed_diff <- mean(subset(all.ages, name == "Fired")$combo)-mean(subset(all.ages, name == "Notfired")$combo)
set.seed(123)
for(i in 1:number_of_permutations)
{
scramble <- sample(all.ages$combo, 51)
frs <- scramble[1:21]
nfrs <- scramble[22:51]
print(c(frs,nfrs))
print("-----------------------------------------------------------------------------------------------")
diff <- mean(frs)-mean(nfrs)
xbarholder[i] <- diff
if(abs(diff) > observed_diff)
counter <- counter + 1
}
Fired = c(34, 37, 37, 38, 41, 42, 43, 44, 44, 45, 45, 45, 46, 48, 49, 53, 53, 54, 54, 55, 56)
Notfired = c(27, 33, 36, 37, 38, 38, 39, 42, 42, 43, 43, 44, 44, 44, 45, 45, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 51, 51, 52, 54)
fired <- rep('Fired', 21)
notfired <- rep('Notfired', 30)
ages <- as.factor(c(fired, notfired))
all.ages <- data.frame(name=ages, combo=c(Fired, Notfired))
number_of_permutations <- 10
xbarholder <- numeric(0)
counter <- 0
observed_diff <- mean(subset(all.ages, name == "Fired")$combo)-mean(subset(all.ages, name == "Notfired")$combo)
set.seed(123)
for(i in 1:number_of_permutations)
{
scramble <- sample(all.ages$combo, 51)
frs <- scramble[1:21]
nfrs <- scramble[22:51]
print(c(frs,nfrs))
print("-----------------------------------------------------------------------------------------------")
diff <- mean(frs)-mean(nfrs)
xbarholder[i] <- diff
if(abs(diff) > observed_diff)
counter <- counter + 1
}
print("----------------------------------------------------------------------------------------------------------")
2+2
??t.test
SMU <- c(34, 1200, 23, 50, 60, 50, 0, 0, 30, 89, 0, 300, 400, 20, 10, 0)
SeattleU <- c(20, 10, 5, 0, 30, 50, 0, 100, 110, 0, 40, 10, 3, 0)
t.test(x = SMU, y = SeattleU, mu = 0, conf.level = .95, alternative = "two.sided", var.equal = T)
len(SMU)
length(SMU)
length(SeattleU)
qt(.975,28)
t.test(x = SMU, y = SeattleU, mu = 0, conf.level = .95, alternative = "two.sided", var.equal = T)
test_results <- t.test(x = SMU, y = SeattleU, mu = 0, conf.level = .95, alternative = "two.sided", var.equal = T)
test_results$statistic
shade(28, h0 = 0, sides = "both", t_calc = test_results$statistic)
?shade
??shade
shade(28, .05, h0 = 0, sides = "both", t_calc = test_results$statistic)
shade(28, .05, h0 = 0, sides = "both", t_calc = round(test_results$statistic, 3))
SMU <- c(34, 1200, 23, 50, 60, 50, 0, 0, 30, 89, 0, 300, 400, 20, 10, 0)
SeattleU <- c(20, 10, 5, 0, 30, 50, 0, 100, 110, 0, 40, 10, 3, 0)
# critical value
qt(.975, 28)
# Two sided, two sample t test
t.test(x = SMU, y = SeattleU, mu = 0, conf.level = .95, alternative = "two.sided", var.equal = T)
t.test
# Shade
shade(28, .05, h0 = 0, sides = "both", t_calc = round(test_results$statistic, 3))
SMU <- c(34, 1200, 23, 50, 60, 50, 0, 0, 30, 89, 0, 300, 400, 20, 10, 0)
SeattleU <- c(20, 10, 5, 0, 30, 50, 0, 100, 110, 0, 40, 10, 3, 0)
# critical value
qt(.975, 28)
# Two sided, two sample t test
test_results <- t.test(x = SMU, y = SeattleU, mu = 0, conf.level = .95, alternative = "two.sided", var.equal = T)
test_results
# Shade
shade(28, .05, h0 = 0, sides = "both", t_calc = round(test_results$statistic, 3))
fishoil <- c(8,12,10,14,2,0,0)
hist(fishoil)
hist(log(fishoil))
regular <- c(-6,0,1,2,-3,-4,2)
hist(regular)
hist(log(regular))
metabolic <- data.frame(PatientType = c(rep('N', 8), rep('T', 7)),
Expenditure = c(20.1, 22.9,18.8,20.9,20.9,22.7,21.4,20,
38.5,25.8,22,23,37.6,30,24.5)
)
View(metabolic)
View(sort(metabolic))
View(sort(metabolic$Expenditure))
View(metabolic)
library(dplyr)
metabolic_sorted <- metabolic %>% arrange(Expenditure)
View(metabolic_sorted)
sum(10:15)
sum(10:15) + 7
sum(1:5) + 6.5 + 6.5 + sum(8:23) + sum(rep(26,5))
406/28
sum(1:3) + 9 + sum(6:15)
120/15
sd(c(1,2,3,4.5,4.5,6,7,8,9,10,11,12,13,14,15))
4.468*sqrt(56/15)
(82.5-56)/8.633
pnorm(-3.07)
.0011*2
81.5-56
25.5/8.633
pnorm(-2.9537)
.0016*2
shade(.05, 1.96)
autism <- data.frame(Child = c(1:9),
Before = c(85,70,40,65,80,75,55,20,70),
After = c(75,50,50,40,20,65,40,25,30))
autism
autism2 <- autism %>% mutate(abs_diff = abs(Before-After)) %>% arrange(abs_diff)
autism2
autism3 <- autism2 %>% mutate(sign  = if_else(Before-After<0, "-", "+"))
autism3
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'greater')
pnorm(2.13, lower.tail = F)
pnorm(2.13270, lower.tail = F)
41-22.5
18.5/8.44
qnorm(2.191943)
pnorm(-2.191943)
coin::wilcoxsign_test(autism$Before ~ autism$After, alternative = 'greater')
41-22.5
18.5/8.44
qnorm(-2.1919)
pnorm(-2.1919)
pnorm(-2.1919) * 2
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided')
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'greater')
shade(8,.05,sides = 'right')
t.test(autism$Before, autism$After, alternative = "greater", paired = T)
Education
df
View(df)
pnorm(-2.1919)
t.test(autism$Before, autism$After, alternative = "greater", paired = T, exact = F)
t.test(autism$Before, autism$After, alternative = "two.sided", paired = T, exact = F)
t.test(autism$Before, autism$After, alternative = "two.sided", paired = T, correct = T)
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided', correct = T)
qnorm(2.25)
pnorm(2.25)
pnorm(-2.25)
pnorm(-2.25118)
pnorm(-2.25118) * 2
stand_dev = sqrt(90*19/24)
stand_dev
pnorm(18/stand_dev, lower.tail = F)
pnorm(18/stand_dev, lower.tail = F) * 2
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided', exact = F)
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided', exact = T)
pnorm(18/stand_dev, lower.tail = F) * 2
pnorm(19/stand_dev, lower.tail = F) * 2
stand_dev = 8.440971508067066
stand_dev
round((sqrt(90*18/24)), 12)
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided', exact = F)
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'greater', exact = F)
stand_dev
pnorm((41-22.5-0.5)/stand_dev, lower.tail = T)
pnorm((41-22.5-0.5)/stand_dev, lower.tail = F)
autism_revised = autism
autism_revised
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'greater')
0.01648469 * 2
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided')
wilcox.test(autism$Before, autism$After, paired = F, alternative = 'two.sided')
wilcox.test(autism$Before, autism$After, paired = T, alternative = 'two.sided')
41-22.5-0.5
18/stand_dev
pnorm(-2.132456) * 2
pnorm(-2.1324) * 2
pnorm(-2.13) * 2
.03236/2
fileLocation <- "http://stat.columbia.edu/~rachel/datasets/nyt10.csv"
data10 <- read.csv(url(fileLocation))
data10$Age_Group <- cut(data1$Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(data10$Age_Group) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
d10 <- subset(data10, Impressions>0)
d10$CTR <- d1$Clicks/d1$Impressions
library(ggplot2)
ggplot(subset(d10, Impressions>0), aes(x=Impressions, fill=Age_Group))+
geom_histogram(binwidth=1)
data10$Age_Group <- cut(data10$Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(data10$Age_Group) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
d10 <- subset(data10, Impressions>0)
d10$CTR <- d1$Clicks/d1$Impressions
library(ggplot2)
ggplot(subset(d10, Impressions>0), aes(x=Impressions, fill=Age_Group))+
geom_histogram(binwidth=1)
data10$Age_Group <- cut(data10$Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(data10$Age_Group) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
d10 <- subset(data10, Impressions>0)
d10$CTR <- d10$Clicks/d1$Impressions
library(ggplot2)
ggplot(subset(d10, Impressions>0), aes(x=Impressions, fill=Age_Group))+
geom_histogram(binwidth=1)
data10$Age_Group <- cut(data10$Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(data10$Age_Group) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
d10 <- subset(data10, Impressions>0)
d10$CTR <- d10$Clicks/d10$Impressions
library(ggplot2)
ggplot(subset(d10, Impressions>0), aes(x=Impressions, fill=Age_Group))+
geom_histogram(binwidth=1)
ggplot(d10, aes(x=Impressions, fill=Age_Group))+
geom_histogram(binwidth=1)
load("/Users/roberthazell/Desktop/DataScience@SMU/DoingDataScience/DDS_HW/Unit6/N-MHSS-2015-DS0001-bndl-data-r/N-MHSS-2015-DS0001-data/N-MHSS-2015-DS0001-data-r.rda")
mhn <- load("/Users/roberthazell/Desktop/DataScience@SMU/DoingDataScience/DDS_HW/Unit6/N-MHSS-2015-DS0001-bndl-data-r/N-MHSS-2015-DS0001-data/N-MHSS-2015-DS0001-data-r.rda")
View(mhn)
rm(mhn)
View(mh2015_puf)
View(mh2015_puf)
mhstates <- unique(mh2015_puf$LST)
mhstates
mhstates <- unique(as.character(mh2015_puf$LST))
mhstates
mhstates <- unique(mh2015_puf$LST) %>% toString()
library(dplyr)
mhstates <- unique(mh2015_puf$LST) %>% toString()
mhstates
mhstates <- unique(mh2015_puf$LST) %>% data.frame()
mhstates
mh_stateabbrev <- unique(mh2015_puf$LST) %>% data.frame()
View(mh_stateabbrev)
mh_stateabbrev <- unique(mh2015_puf$LST) %>% data.frame() %>% colnames("State")
mh_stateabbrev <- unique(mh2015_puf$LST) %>% data.frame() %>% `colnames<-`(State)
mh_stateabbrev <- unique(mh2015_puf$LST) %>% data.frame() %>% `colnames<-`('State')
rm(mhstates)
not_mainland <- c('AS', 'GU', 'PR', 'VI', 'AK', 'HI')
mh2015_mainland <- mh2015_puf %>% filter(LST != not_mainland)
mh2015_mainland <- mh2015_puf %>% filter(LST !not_mainland)
mh2015_mainland <- mh2015_puf %>% filter(LST != not_mainland)
mh2015_mainland <- mh2015_puf %>% %>% group_by(LST) %>% filter(LST != not_mainland)
mh2015_mainland <- mh2015_puf %>% group_by(LST) %>% filter(LST != not_mainland)
mh2015_mainland <- mh2015_puf %>% filter(!LST %in% not_mainland)
mh2015_mainland <- mh2015_puf %>% filter(!LST %in% not_mainland) %>% group_by(LST) %>% summarise(StateTotal = length(LST))
View(mh2015_mainland)
mh2015_mainland <- mh2015_puf %>% filter(LST %in% not_mainland)
mh2015_mainland
View(mh2015_mainland)
not_mainland <- c('AS', 'GU', 'PR', 'VI', 'AK', 'HI')
mh2015_mainland <- mh2015_puf %>% filter(LST %in% not_mainland)
mh2015_mainland
View(mh2015_mainland)
colnames(mh2015_puf)
'HI' in mh2015_puf
'HI' %in% mh2015_puf
'HI' %in% mh2015_puf$LST
'AZ' %in% mh2015_puf$LST
str(mh2015_puf)
mh2015_puf$LST <- as.character(mh2015_puf$LST)
mh_stateabbrev <- unique(mh2015_puf$LST) %>% data.frame() %>% `colnames<-`('State')
not_mainland <- c('AS', 'GU', 'PR', 'VI', 'AK', 'HI')
mh2015_mainland <- mh2015_puf %>% filter(LST %in% not_mainland)
mh2015_mainland
'HI' in mh2015_puf
'AZ' %in% mh2015_puf$LST
head(str(mh2015_puf)
)
mh2015_puf$LST <- as_tibble(mh2015_puf$LST)
'AZ' %in% mh2015_puf$LST
str(mh2015_puf)
View(mh2015_puf)
View(mh2015_puf)
str(mh2015_puf)
rm(mh2015_puf)
load("/Users/roberthazell/Desktop/DataScience@SMU/DoingDataScience/DDS_HW/Unit6/N-MHSS-2015-DS0001-bndl-data-r/N-MHSS-2015-DS0001-data/N-MHSS-2015-DS0001-data-r.rda")
View(mh2015_puf)
View(mh2015_puf)
str(mh2015_puf)
library(dplyr)
mh2015_puf$LST <- mh2015_puf$LST %>% trimws("right")
str(mh2015_puf)
mh2015_mainland <- mh2015_puf %>% filter(!LST %in% not_mainland)
not_mainland <- c('AS', 'GU', 'PR', 'VI', 'AK', 'HI')
mh2015_mainland <- mh2015_puf %>% filter(!LST %in% not_mainland)
View(mh2015_mainland)
str(mh2015_mainland)
'HI' %in% mh2015_puf
'HI' %in% mh2015_puf$LST
'HI' %in% mh2015_mainland$LST
not_mainland %>in% mh2015_mainland$LST
not_mainland %in% mh2015_mainland$LST
library(readr)
ex0525 <- read_csv("Desktop/DataScience@SMU/StatFoundations/Ch5/ex0525.csv")
View(ex0525)
library(dplyr)
ex0525 %>% group_by(Educ) %>% summarise(MeanIncome = mean(Income2005))
ex0525 %>% mutate(logIncome2005 = log(Income2005) %>% group_by(Educ) %>% summarise(MedianIncome = mean(logIncome2005))
)
ex0525 %>% mutate(logIncome2005 = log(Income2005)) %>% group_by(Educ) %>% summarise(MedianIncome = mean(logIncome2005))
ex0525 %>% group_by(Educ) %>% summarise(MedianIncome = median(Income2005))
install.packages("agricolae")
install.packages("agricolae")
install.packages("agricolae")
install.packages("agricolae")
library(agricolae)
library(agricolae)
library(agricolae)
beer_landscape[2,3]
---
title: "Beer Analysis"
author: "Robert Hazell"
date: "2/27/2019"
output:
html_document:
keep_md: true
---
```{r include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message = FALSE)
```
## XYZ Brewery Proposal
### Introduction
According to [Fortune](http://fortune.com/2018/03/27/craft-beer-2017-sales/) the US Craft Brew industry was worth $26 billion dollars in 2017, an increase of $6.2 billion since 2015.  While the pace of growth is slowing, opportunity is still large.  It's known that craft beer drinkers tend to support local independent breweries, and consumers are becoming more selective.  Furthermore there is [rising demand](https://www.grandviewresearch.com/press-release/global-craft-beer-market) for low alcohol by volume (ABV) and flavored beer.  Each market share of .5%  is equivalent to $130 million in revenue.
As a startup XYZ faces a saturated market.  There are two purposes of this research, first of which is to examine the current landscape and scope out underserved areas in the US where few breweries exist.   Second is to understand what beer preference(s) would be most profitable should a brewery (or breweries) be built.  [Craftbeer](https://www.craftbeer.com/craft-beer-muses/craft-beer-by-the-numbers) reports that four key statistics are used to describe craft beers:
**1)** Serving size
**2)** International Bitterness Units (IBU): the bitterness element of a beer's flavor
**3)** Alcohol by Volume (ABV): higher values increase the complexity and flavor of the beer
**4)** Original Gravity / Final Gravity: factors which affect ABV and sensory intensity
This report will focus on IBU and ABV. It will also integrate data on drinking consumption by state to clarify each state's drinking behavior.
### Competitive Landscape: How many craft breweries are currently producing in the US?
The relevant datasets are *Beers.csv* and *Breweries.csv*.  Each will be loaded each into R after setting a working a directory.
```{r}
setwd("/Users/roberthazell/Desktop/DataScience@SMU/DoingDataScience/CaseStudy1")
beers <- read.csv("beers.csv")
brewers <- read.csv("breweries.csv")
```
The total number of breweries can be found be inspecting the ```State``` column of ```brewers```.  There are 558 unique breweriss in the U.S.
```{r}
length(brewers$State)
```
### Combining data sources to better understand US craft brewing
By merging the *beers* and *brewers* datasets, a more complete picture of the US beer landscape is possible.  Each dataset will be merged on their common *id* columns.  This is ```Brewery_id``` and ```Brew_ID```, which are equivalent.
```{r}
Brewtot <- merge(beers, brewers, by.x = "Brewery_id", by.y = "Brew_ID")
```
Here is a look at the first six rows of the merged data, as there are over 2000 rows in the dataset.
```{r}
nrow(Brewtot) # number of rows
head(Brewtot) # first six observations
```
Renaming ```Name.x``` and ```Name.y``` increases clarity. They will represent the ```Beer``` name and ```Brewer```, respectively.
```{r}
colnames(Brewtot)[c(2,8)] = c("Beer", "Brewer")
```
### Missing Information
Before further analyzing the data it's best to see if any missing values (```NA```) exist.
```{r}
Brewtot_Missing <- sapply(Brewtot, function(x) sum(is.na(x)))
Brewtot_Missing
```
On the two important metrics ```ABV``` and ```IBU```, there are 62 and 1005 missing values respectively.  This means our data may have limitations, namely it may not be completely representative of the entire brewing industry. As will be shown later, however, there is much utility still.
### Market Saturation
In determining where to build any brewery, it's advisable to avoid states with many breweries already.  To that end, the merged dataset ```Brewtot``` can be used to summarize the total number of unique brews and brewers per state.
```{r}
library(dplyr)
library(kableExtra)
beer_landscape <- Brewtot %>% group_by(State) %>% summarise(Beers = length(Beer)) %>% cbind(brewers %>% group_by(State) %>% summarise(`Total Brewers` = length(State)) %>% select(`Total Brewers`)) %>% arrange(desc(`Total Brewers`))
kable(beer_landscape, align = rep('c',3)) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```
From this we see Colorado has the highest number of beers and breweries.  So XYZ should probably avoid that state!
### General Differences in Beer Characteristics
Before looking at state and regional differences in IBU and ABV, an overall view of their distribution is helpful.
```{r}
hist(Brewtot$ABV, main="Distribution of ABV", breaks=20, xlab="Alcohol by Volume", border="black", col="steel blue", xlim=c(.02,.13))
hist(Brewtot$IBU, main="Distribution of IBU", breaks=20, xlab="International Bitterness Units", border="black", col="dark red", xlim=c(0,100))
```
ABV is mostly centered around .05, with a moderate right skew.  On the other hand, IBU has a strong right skew.  In spite of the peak at ~ 20 IBU, a lot of beers have a bitter side, too.
### State Differences in Beer Characteristics
Perhaps ABV and/or IBU stabilizes when *median* values are examined.  That data needs gathering first.
```{r}
alcohol_and_bitterness <- Brewtot %>% group_by(State) %>%
summarise(MedianAlcohol = median(ABV, na.rm = T), MedianBitter = median(IBU, na.rm = T))
```
South Dakota has absolutely no information on bitterness for their beers, so it will be deleted.
```{r}
alcohol_and_bitterness <- alcohol_and_bitterness[-42,]
```
Here are the median distributions for IBU and ABV by state.
```{r}
library(ggplot2)
ggplot(alcohol_and_bitterness) +
geom_col(aes(x = reorder(State, MedianAlcohol), y = MedianAlcohol), fill = 'steel blue') + coord_flip() + ylab("Median ABV") + xlab("State") + ggtitle("Median Alcohol Volume by State") + theme(plot.title = element_text(hjust = 0.5))
ggplot(alcohol_and_bitterness) +
geom_col(aes(x = reorder(State, MedianBitter), y = MedianBitter), fill = 'orange') + coord_flip() + ylab("Median IBU") + xlab("State") + ggtitle("Median Beer Bitterness by State") +  theme(plot.title = element_text(hjust = 0.5))
```
This confirms the assumption that at least one of the variables stabilize when median values are examined (in this case, ABV).  Nevertheless, median IBU still displays significant variation, with Maine featuring a median IBU more than triple that of Wisconsin's.
### Regional Differences in Beer Characteristics
What if median bitterness of beer brewed different at a regional level?  Let's test this claim.
First, define the four US regions according to the [Census Bureau's](https://www.businessinsider.com/regions-of-united-states-2018-5) standards.
```{r}
northeast = c('ME', 'NH', 'VT', 'MA', 'RI', 'CT', 'NY', 'NJ', 'PA')
midwest = c('ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'MI', 'IN', 'OH')
south = c('DE', 'MD', 'VA', 'WV', 'KY', 'NC', 'SC', 'TN', 'GA', 'FL', 'AL', 'MS', 'AR', 'LA', 'TX', 'OK')
west = c('WA', 'OR', 'ID', 'MT', 'WY', 'CA', 'NV', 'UT', 'AZ', 'CO', 'NM', 'AK', 'HI')
```
Something worth noting is that whitespace needs to be removed from the ```State``` column of ```Brewtot```.  Take a look at ```Brewtot```'s structure.
```{r}
str(Brewtot)
```
Looking closely at ```State```, one can see each state abbreviation has a blank space to the far left.  That'll be removed first, and then the ```Brewtot``` will be categorized by state.
```{r}
Brewtot$State <- trimws(Brewtot$State, which = "left")
Brewtot = Brewtot %>% mutate(Region = ifelse(State %in% northeast, 'Northeast',
ifelse(State %in% midwest, 'Midwest',
ifelse(State %in% south, 'South', 'West')))
)
```
Here are 10 random rows from the 'regionalized' dataset.  Only ```Beer```, ```Brewer```, ```State```, and ```Region``` columns are selected.
```{r}
set.seed(101)
Brewtot %>% select(c(Beer, Brewer, State, Region)) %>%
sample_n(10) %>% kable(align = rep('c',4)) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```
Now the median IBU and ABV values will be plotted as a bar chart.
```{r}
alcohol_and_bitterness_regionalized <- Brewtot %>% select(c(Beer, Brewer, State, Region, ABV, IBU)) %>%
group_by(Region) %>% summarise(MedianAlcohol = median(ABV, na.rm = T), MedianBitter = median(IBU, na.rm = T))
alcohol_and_bitterness_regionalized$Region <- as.factor(alcohol_and_bitterness_regionalized$Region)
ggplot(alcohol_and_bitterness_regionalized) + geom_col(aes(Region, MedianBitter, fill = Region)) + ggtitle("Median Bitterness of Beer by Region") + ylab("Median Bitterness") + theme(plot.title = element_text(hjust = 0.5))
ggplot(alcohol_and_bitterness_regionalized) + geom_col(aes(Region, MedianAlcohol, fill = Region)) + ggtitle("Median ABV of Beer by Region") + ylab("Median Alcohol Content") + theme(plot.title = element_text(hjust = 0.5))
```
Median ABV values look constant by region, but some differences in median bitterness (IBU) exists across region.  Midwestern beers seem the least bitter while Western beers are bitter by far.
### Relationship between ABV and IBU
Much discussion has been given to these beer characteristics above, but is there any correlation between these variables?  Here's a scatterplot comparing them.
```{r}
ggplot(data=Brewtot, aes(x=IBU, y=ABV)) +geom_point(shape = 16, size = 2, color="blue") + stat_smooth(method = 'lm', color='red') + labs(title = 'Craft Beer IBU by ABV') + theme(plot.title = element_text(hjust = 0.5))
```
There is a moderate linear correlation.  A Pearson correlation test quantifies it.
```{r}
cor.test( ~ ABV + IBU,data=Brewtot,method = "pearson")
```
At *r* = 0.67, this is indeed moderate, but not strong, positive correlation. The regression line illustrates that the variability may be changing along the prediction line (heteroscedasticity).  This correlation does not show causation as the relationship may be affect by third variables such as ingredients used, fermentaiton process, and marketing needs.
### Integrating Beer Consumption
It's plausible to think that states with higher numbers of brewers or beers have higher beer consumption.  To investigate this assumption, 2018 [data](https://www.usatoday.com/story/money/personalfinance/2018/05/02/which-states-residents-drink-most-beer/569430002/) on total annual beer consumption (in gallons) by state is taken.
Note that the year for the ```beer``` and ```brewers``` data is unknown, but we'll assume the general trend of data has not changed significantly even if the data are a couple of years apart.
```{r}
library(rvest)
library(stringr)
# scrape consumption info
scraping_beer <- read_html("https://www.usatoday.com/story/money/personalfinance/2018/05/02/which-states-residents-drink-most-beer/569430002/")
national_consum <- scraping_beer %>% html_nodes("ul") %>% html_text() %>% data.frame()
colnames(national_consum)[1] <- "Total Consumption"
# remove first four rows (irrelevant info)
# use drop = FALSE since there's only 1 column
national_consum <- national_consum[-c(1:4), , drop = FALSE]
# change column from factor to string (character)
national_consum$`Total Consumption` <- as.character(national_consum$`Total Consumption`)
beer_values = c() # holds the actual consumption values
for (row in national_consum){
total_consum <- substring(row, first = str_locate(row, "Total")[1], last = str_locate(row, "5 yr.")[1] - 1)
total_consum_numeric <- regmatches(total_consum, regexpr('\\d+\\.+\\d', total_consum)) %>% as.numeric()
beer_values <- c(beer_values, total_consum_numeric)
}
# make the beer values the column values of nationa_consum
national_consum$`Total Consumption` <- beer_values
# remove row names bc of improper numbering
rownames(national_consum) <- NULL
# scrape the name of the states
scraping_states <- read_html("https://www.usatoday.com/story/money/personalfinance/2018/05/02/which-states-residents-drink-most-beer/569430002/")
statenames <- scraping_states %>% html_nodes("p") %>% html_text() %>% data.frame()
# remove row names
colnames(statenames)[1] <- 'State'
statenames$State <- as.character(statenames$State)
rownames(statenames) <- NULL
# immediately delete irrelevant first 22 and last 4 rows
statenames <- statenames[-c(1:22, 88:91), 1, drop = FALSE]
# first isolate rows similar in format to "46. New York"
statenames <- statenames[grepl("\\d+\\.", statenames$State), , drop = FALSE]
# remove list numbers and "(tied)"
statenames$State <- str_replace_all(statenames$State, "\\d+\\.|\\(+tied+\\)", "")
# remove spaces before or after name
statenames$State <- str_replace_all(statenames$State, "^\\s|\\s$", "")
rownames(statenames) <- NULL
# convert to abbreviations using state.name and state.abb built-ins
for (i in 1:nrow(statenames)) {
statenames$State[i] <- state.abb[grep(statenames$State[i], state.name)]
}
# merge statenames and national_consum to a unified dataset
national_consum <- cbind(national_consum, statenames)
national_consum
beer_landscape[2,3]
beer_landscape[2,3]
beer_landscape[2,1]
beer_landscape <- Brewtot %>% group_by(State) %>% summarise(Beers = length(Beer)) %>% cbind(brewers %>% group_by(State) %>% summarise(`Total Brewers` = length(State)) %>% select(`Total Brewers`)) %>% arrange(desc(`Total Brewers`))
str(beer_landscape)
beer_landscape[2,1]
kable(beer_landscape, align = rep('c',3)) %>% kable_styling(bootstrap_options = "striped", full_width = F)
beer_landscape[2,1]
beer_landscape[2,1]
str(complete_beer_landscape)
ggplot(complete_beer_landscape) + geom_point(aes(`Total.Brewers`, `Total Consumption`))
complete_beer_landscape[which(`Total.Brewers` > 40 && ``Total Consumption` > 100), 1]
complete_beer_landscape[which(`Total.Brewers` > 40 && `Total Consumption` > 100), 1]
library(knitr)
purl("BeerAnalysis.Rmd")
getwd()
open("BeerAnalysis.R")
purl("BeerAnalysis.Rmd")
